{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7b0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "yearsToRead = [2018,2019,2020,2021,2022]\n",
    "#yearsToRead = [2020]\n",
    "readPath = '/export/ml4ds/teddata/temporal/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#leemos el primer año y así ya tenemos la estructura inicial para poder concatenarlos:\n",
    "first = yearsToRead.pop()\n",
    "print (first)\n",
    "tedDF = spark.read.parquet (readPath + str(first))\n",
    "\n",
    "for year in yearsToRead:\n",
    "    print (year)\n",
    "    tedDF = tedDF.unionAll (spark.read.parquet (readPath + str(year)))\n",
    "\n",
    "    #tedDF = spark.read.parquet (readPath + str(year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c71cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tedDF.createOrReplaceTempView(\"TedFormTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72ab43-fc47-4acf-a34a-6eb9249750cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=================================================>   (216 + 13) / 229]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Licitaciones totales: 2553626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Número de licitaciones totales:\n",
    "##################\n",
    "\n",
    "print ('Licitaciones totales: %s' % tedDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f26d1e1-059c-4a14-bff2-432b51e3f12d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nextraneous input ')' expecting {'ADD', 'AFTER', 'ALL', 'ALTER', 'ANALYZE', 'AND', 'ANTI', 'ANY', 'ARCHIVE', 'ARRAY', 'AS', 'ASC', 'AT', 'AUTHORIZATION', 'BETWEEN', 'BOTH', 'BUCKET', 'BUCKETS', 'BY', 'CACHE', 'CASCADE', 'CASE', 'CAST', 'CHANGE', 'CHECK', 'CLEAR', 'CLUSTER', 'CLUSTERED', 'CODEGEN', 'COLLATE', 'COLLECTION', 'COLUMN', 'COLUMNS', 'COMMENT', 'COMMIT', 'COMPACT', 'COMPACTIONS', 'COMPUTE', 'CONCATENATE', 'CONSTRAINT', 'COST', 'CREATE', 'CROSS', 'CUBE', 'CURRENT', 'CURRENT_DATE', 'CURRENT_TIME', 'CURRENT_TIMESTAMP', 'CURRENT_USER', 'DAY', 'DATA', 'DATABASE', DATABASES, 'DBPROPERTIES', 'DEFINED', 'DELETE', 'DELIMITED', 'DESC', 'DESCRIBE', 'DFS', 'DIRECTORIES', 'DIRECTORY', 'DISTINCT', 'DISTRIBUTE', 'DIV', 'DROP', 'ELSE', 'END', 'ESCAPE', 'ESCAPED', 'EXCEPT', 'EXCHANGE', 'EXISTS', 'EXPLAIN', 'EXPORT', 'EXTENDED', 'EXTERNAL', 'EXTRACT', 'FALSE', 'FETCH', 'FIELDS', 'FILTER', 'FILEFORMAT', 'FIRST', 'FOLLOWING', 'FOR', 'FOREIGN', 'FORMAT', 'FORMATTED', 'FROM', 'FULL', 'FUNCTION', 'FUNCTIONS', 'GLOBAL', 'GRANT', 'GROUP', 'GROUPING', 'HAVING', 'HOUR', 'IF', 'IGNORE', 'IMPORT', 'IN', 'INDEX', 'INDEXES', 'INNER', 'INPATH', 'INPUTFORMAT', 'INSERT', 'INTERSECT', 'INTERVAL', 'INTO', 'IS', 'ITEMS', 'JOIN', 'KEYS', 'LAST', 'LATERAL', 'LAZY', 'LEADING', 'LEFT', 'LIKE', 'LIMIT', 'LINES', 'LIST', 'LOAD', 'LOCAL', 'LOCATION', 'LOCK', 'LOCKS', 'LOGICAL', 'MACRO', 'MAP', 'MATCHED', 'MERGE', 'MINUTE', 'MONTH', 'MSCK', 'NAMESPACE', 'NAMESPACES', 'NATURAL', 'NO', NOT, 'NULL', 'NULLS', 'OF', 'ON', 'ONLY', 'OPTION', 'OPTIONS', 'OR', 'ORDER', 'OUT', 'OUTER', 'OUTPUTFORMAT', 'OVER', 'OVERLAPS', 'OVERLAY', 'OVERWRITE', 'PARTITION', 'PARTITIONED', 'PARTITIONS', 'PERCENT', 'PIVOT', 'PLACING', 'POSITION', 'PRECEDING', 'PRIMARY', 'PRINCIPALS', 'PROPERTIES', 'PURGE', 'QUERY', 'RANGE', 'RECORDREADER', 'RECORDWRITER', 'RECOVER', 'REDUCE', 'REFERENCES', 'REFRESH', 'RENAME', 'REPAIR', 'REPLACE', 'RESET', 'RESPECT', 'RESTRICT', 'REVOKE', 'RIGHT', RLIKE, 'ROLE', 'ROLES', 'ROLLBACK', 'ROLLUP', 'ROW', 'ROWS', 'SECOND', 'SCHEMA', 'SELECT', 'SEMI', 'SEPARATED', 'SERDE', 'SERDEPROPERTIES', 'SESSION_USER', 'SET', 'MINUS', 'SETS', 'SHOW', 'SKEWED', 'SOME', 'SORT', 'SORTED', 'START', 'STATISTICS', 'STORED', 'STRATIFY', 'STRUCT', 'SUBSTR', 'SUBSTRING', 'SYNC', 'TABLE', 'TABLES', 'TABLESAMPLE', 'TBLPROPERTIES', TEMPORARY, 'TERMINATED', 'THEN', 'TIME', 'TO', 'TOUCH', 'TRAILING', 'TRANSACTION', 'TRANSACTIONS', 'TRANSFORM', 'TRIM', 'TRUE', 'TRUNCATE', 'TRY_CAST', 'TYPE', 'UNARCHIVE', 'UNBOUNDED', 'UNCACHE', 'UNION', 'UNIQUE', 'UNKNOWN', 'UNLOCK', 'UNSET', 'UPDATE', 'USE', 'USER', 'USING', 'VALUES', 'VIEW', 'VIEWS', 'WHEN', 'WHERE', 'WINDOW', 'WITH', 'YEAR', 'ZONE', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 45)\n\n== SQL ==\nSELECT EntidadAdjudicadora['Sitio web'].keys()  FROM TedFormTable  WHERE EntidadAdjudicadora['Sitio web'] IS NOT NULL  \n---------------------------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#data =spark.sql (\"SELECT * FROM TedFormTable\").take(1)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#data =spark.sql (\"SELECT * FROM TedFormTable WHERE DatosGeneralesDelExpediente['Numero del expediente']='2022/S 056-145414'\").collect()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT EntidadAdjudicadora[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSitio web\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m].keys()  FROM TedFormTable  WHERE EntidadAdjudicadora[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSitio web\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m] IS NOT NULL  \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m400\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark-3.2.0-bin-3.3.0/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/opt/spark-3.2.0-bin-3.3.0/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark-3.2.0-bin-3.3.0/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nextraneous input ')' expecting {'ADD', 'AFTER', 'ALL', 'ALTER', 'ANALYZE', 'AND', 'ANTI', 'ANY', 'ARCHIVE', 'ARRAY', 'AS', 'ASC', 'AT', 'AUTHORIZATION', 'BETWEEN', 'BOTH', 'BUCKET', 'BUCKETS', 'BY', 'CACHE', 'CASCADE', 'CASE', 'CAST', 'CHANGE', 'CHECK', 'CLEAR', 'CLUSTER', 'CLUSTERED', 'CODEGEN', 'COLLATE', 'COLLECTION', 'COLUMN', 'COLUMNS', 'COMMENT', 'COMMIT', 'COMPACT', 'COMPACTIONS', 'COMPUTE', 'CONCATENATE', 'CONSTRAINT', 'COST', 'CREATE', 'CROSS', 'CUBE', 'CURRENT', 'CURRENT_DATE', 'CURRENT_TIME', 'CURRENT_TIMESTAMP', 'CURRENT_USER', 'DAY', 'DATA', 'DATABASE', DATABASES, 'DBPROPERTIES', 'DEFINED', 'DELETE', 'DELIMITED', 'DESC', 'DESCRIBE', 'DFS', 'DIRECTORIES', 'DIRECTORY', 'DISTINCT', 'DISTRIBUTE', 'DIV', 'DROP', 'ELSE', 'END', 'ESCAPE', 'ESCAPED', 'EXCEPT', 'EXCHANGE', 'EXISTS', 'EXPLAIN', 'EXPORT', 'EXTENDED', 'EXTERNAL', 'EXTRACT', 'FALSE', 'FETCH', 'FIELDS', 'FILTER', 'FILEFORMAT', 'FIRST', 'FOLLOWING', 'FOR', 'FOREIGN', 'FORMAT', 'FORMATTED', 'FROM', 'FULL', 'FUNCTION', 'FUNCTIONS', 'GLOBAL', 'GRANT', 'GROUP', 'GROUPING', 'HAVING', 'HOUR', 'IF', 'IGNORE', 'IMPORT', 'IN', 'INDEX', 'INDEXES', 'INNER', 'INPATH', 'INPUTFORMAT', 'INSERT', 'INTERSECT', 'INTERVAL', 'INTO', 'IS', 'ITEMS', 'JOIN', 'KEYS', 'LAST', 'LATERAL', 'LAZY', 'LEADING', 'LEFT', 'LIKE', 'LIMIT', 'LINES', 'LIST', 'LOAD', 'LOCAL', 'LOCATION', 'LOCK', 'LOCKS', 'LOGICAL', 'MACRO', 'MAP', 'MATCHED', 'MERGE', 'MINUTE', 'MONTH', 'MSCK', 'NAMESPACE', 'NAMESPACES', 'NATURAL', 'NO', NOT, 'NULL', 'NULLS', 'OF', 'ON', 'ONLY', 'OPTION', 'OPTIONS', 'OR', 'ORDER', 'OUT', 'OUTER', 'OUTPUTFORMAT', 'OVER', 'OVERLAPS', 'OVERLAY', 'OVERWRITE', 'PARTITION', 'PARTITIONED', 'PARTITIONS', 'PERCENT', 'PIVOT', 'PLACING', 'POSITION', 'PRECEDING', 'PRIMARY', 'PRINCIPALS', 'PROPERTIES', 'PURGE', 'QUERY', 'RANGE', 'RECORDREADER', 'RECORDWRITER', 'RECOVER', 'REDUCE', 'REFERENCES', 'REFRESH', 'RENAME', 'REPAIR', 'REPLACE', 'RESET', 'RESPECT', 'RESTRICT', 'REVOKE', 'RIGHT', RLIKE, 'ROLE', 'ROLES', 'ROLLBACK', 'ROLLUP', 'ROW', 'ROWS', 'SECOND', 'SCHEMA', 'SELECT', 'SEMI', 'SEPARATED', 'SERDE', 'SERDEPROPERTIES', 'SESSION_USER', 'SET', 'MINUS', 'SETS', 'SHOW', 'SKEWED', 'SOME', 'SORT', 'SORTED', 'START', 'STATISTICS', 'STORED', 'STRATIFY', 'STRUCT', 'SUBSTR', 'SUBSTRING', 'SYNC', 'TABLE', 'TABLES', 'TABLESAMPLE', 'TBLPROPERTIES', TEMPORARY, 'TERMINATED', 'THEN', 'TIME', 'TO', 'TOUCH', 'TRAILING', 'TRANSACTION', 'TRANSACTIONS', 'TRANSFORM', 'TRIM', 'TRUE', 'TRUNCATE', 'TRY_CAST', 'TYPE', 'UNARCHIVE', 'UNBOUNDED', 'UNCACHE', 'UNION', 'UNIQUE', 'UNKNOWN', 'UNLOCK', 'UNSET', 'UPDATE', 'USE', 'USER', 'USING', 'VALUES', 'VIEW', 'VIEWS', 'WHEN', 'WHERE', 'WINDOW', 'WITH', 'YEAR', 'ZONE', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 45)\n\n== SQL ==\nSELECT EntidadAdjudicadora['Sitio web'].keys()  FROM TedFormTable  WHERE EntidadAdjudicadora['Sitio web'] IS NOT NULL  \n---------------------------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "#data =spark.sql (\"SELECT * FROM TedFormTable\").take(1)\n",
    "#data =spark.sql (\"SELECT * FROM TedFormTable WHERE DatosGeneralesDelExpediente['Numero del expediente']='2022/S 056-145414'\").collect()\n",
    "data =spark.sql (\"SELECT EntidadAdjudicadora['Sitio web'].keys()  FROM TedFormTable  WHERE EntidadAdjudicadora['Sitio web'] IS NOT NULL  \").take(400)\n",
    "#data =spark.sql (\"SELECT FORM_ID, COUNT(FORM_ID) FROM TedFormTable WHERE EntidadAdjudicadora['Sitio web'] IS NOT NULL GROUP BY FORM_ID ORDER BY RAND() \").take(400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebd5bea6-055b-40ee-8c04-2d7510bc3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data =spark.sql (\"SELECT * FROM TedFormTable WHERE DatosGeneralesDelExpediente['NOTICE_DATA']['NO_DOC_OJS']='2022/S 056-145414'\").take(10)\n",
    "#data =spark.sql (\"SELECT AWARD_CONTRACT FROM TedFormTable ORDER BY RAND()\").limit(100).rdd.map(lambda row: row.asDict()).collect()\n",
    "#data =spark.sql (\"SELECT FORM_ID, COUNT(FORM_ID) FROM TedFormTable WHERE CODED_DATA_SECTION['NOTICE_DATA']['IA_URL_ETENDERING'] IS NOT NULL GROUP BY FORM_ID ORDER BY RAND() \").take(400)\n",
    "#data =spark.sql (\"SELECT FORM_ID, COUNT(FORM_ID) FROM TedFormTable WHERE CODED_DATA_SECTION['NOTICE_DATA']['VALUES'] IS NOT NULL GROUP BY FORM_ID ORDER BY RAND() \").take(400)\n",
    "#data2 =spark.sql (\"SELECT * FROM TedFormTable WHERE CODED_DATA_SECTION['NOTICE_DATA']['NO_DOC_OJS']='2022/S 084-228291'\").rdd.map(lambda row: row.asDict()).collect()\n",
    "#data2 =spark.sql (\"SELECT AWARD_CONTRACT FROM TedFormTable WHERE SIZE (AWARD_CONTRACT)>0 ORDER BY RAND()\").limit(100).rdd.map(lambda row: row.asDict()).collect()\n",
    "#data2 =spark.sql (\"SELECT * FROM TedFormTable  ORDER BY RAND()\").limit(100).rdd.map(lambda row: row.asDict()).collect()\n",
    "#data2 =spark.sql (\"SELECT * FROM TedFormTable WHERE Ted_doc_id='184248-2018' LIMIT 100\").rdd.map(lambda row: row.asDict()).collect()\n",
    "#data2 =spark.sql (\"SELECT COUNT(EntidadAdjudicadora['Sitio web']) AS Num, EntidadAdjudicadora['Sitio web'] AS Web FROM TedFormTable GROUP BY EntidadAdjudicadora['Sitio web'] ORDER BY Num DESC\").rdd.map(lambda row: row.asDict()).collect()\n",
    "data2 =spark.sql (\"SELECT DatosGeneralesDelExpediente['Valor estimado del contrato'] FROM TedFormTable WHERE DatosGeneralesDelExpediente['Valor estimado del contrato'] <> '\"\"' LIMIT 100 \").collect()\n",
    "#data2 =spark.sql (\"SELECT COUNT(CONTRACTING_BODY['ADDRESS_CONTRACTING_BODY']['OFFICIALNAME']) AS Num, CONTRACTING_BODY['ADDRESS_CONTRACTING_BODY']['OFFICIALNAME'] AS Web FROM TedFormTable GROUP BY CONTRACTING_BODY['ADDRESS_CONTRACTING_BODY']['OFFICIALNAME'] ORDER BY Num DESC\").rdd.map(lambda row: row.asDict()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b18f1efc-15bf-4432-bbd3-277ee979d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(EntidadAdjudicadora[Sitio web][0]=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[0]['CODED_DATA_SECTION']\n",
    "import json\n",
    "data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa3cf5-efe8-4504-b9b2-041e6d037448",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5199ac9-dc02-41fd-9f52-eab9be89717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_data.json') as json_file:\n",
    "    data = json.load(lista)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91156f3c-e16c-49aa-ae09-552bba0157bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql (\"SELECT FORM_ID, COUNT(FORM_ID) FROM TedFormTable WHERE CODED_DATA_SECTION['NOTICE_DATA']['IA_URL_ETENDERING'] IS NOT NULL GROUP BY FORM_ID ORDER BY RAND() \").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29268d87-b523-47fb-8d38-21c835d8665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql (\"SELECT FORM_ID, COUNT(FORM_ID) FROM TedFormTable WHERE CODED_DATA_SECTION['NOTICE_DATA']['IA_URL_ETENDERING'] IS NOT NULL GROUP BY FORM_ID ORDER BY RAND() \").take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2507231-2952-47fa-b659-5ce1f05d40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123890a-26d9-484c-b69f-86519127f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = tedDF.rdd.map(lambda row: row.asDict()).take(400)\n",
    "data_F = spark.sql(\"SELECT * FROM TedFormTable WHERE FORM_ID='F02_2014' ORDER BY RAND()\" ).rdd.map(lambda row: row.asDict()).take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c121aa8-9bb6-4454-853b-c70eb89e3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for data in data_F:\n",
    "    data['OBJECT_CONTRACT_ORIGINAL'] = json.loads(data['OBJECT_CONTRACT_ORIGINAL'])\n",
    "    #for data2 in data['OBJECT_CONTRACT_ORIGINAL']:\n",
    "    #    data2['OBJECT_DESCR'] = json.loads (data2['OBJECT_DESCR'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752ae46-85fe-4d54-ae30-56d0f46c9738",
   "metadata": {},
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613dd4a5-8436-4f03-b746-d495b56db557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('F03.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5092ab4-ecc2-40bc-a72a-a9edba44ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "allkeys = {}\n",
    "\n",
    "def returnType (valor):\n",
    "    if type (data[clave1]) == str:\n",
    "        return 'STRING'\n",
    "    if type (data[clave1]) == dict:\n",
    "        return 'DICT'\n",
    "    if type (data[clave1]) == list:\n",
    "        return 'LIST'\n",
    "    \n",
    "    return 'UNK'\n",
    "\n",
    "for data in data_F[:1]:\n",
    "    for clave1 in data.keys():\n",
    "        typedata = returnType( data[clave1])\n",
    "        allkeys[clave1] = typedata\n",
    "        if typedata == 'DICT':\n",
    "            allkeys[clave1] = []\n",
    "            for clave2 in data[clave1]:\n",
    "                typedata2 = returnType( data[clave1][clave2])\n",
    "                allkeys[clave1].append( {clave2, typedata2})\n",
    "                #if typedata2 == 'DICT':\n",
    "                #        typedata3 = returnType( data[clave1][clave2])\n",
    "                #        allkeys[clave1] = {clave2, 'DICT'}\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d7cb1-0ab4-479d-b251-249bd2fe150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "print(yaml.dump(data_F[20], default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431fdc0-1044-4e7a-9b8b-19d54241a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F = spark.sql(\"SELECT * FROM TedFormTable\" ).rdd.map(lambda row: row.asDict()).take(2000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caeb314-09b6-4039-85b5-162c9f3b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import collections # requires Python 2.7 -- see note below if you're using an earlier version\n",
    "def merge_dict(d1, d2):\n",
    "    \"\"\"\n",
    "    Modifies d1 in-place to contain values from d2.  If any value\n",
    "    in d1 is a dictionary (or dict-like), *and* the corresponding\n",
    "    value in d2 is also a dictionary, then merge them in-place.\n",
    "    \"\"\"\n",
    "    for k,v2 in d2.items():\n",
    "        v1 = d1.get(k) # returns None if v1 has no value for this key\n",
    "        if ( isinstance(v1, collections.Mapping) and \n",
    "             isinstance(v2, collections.Mapping) ):\n",
    "            merge_dict(v1, v2)\n",
    "        else:\n",
    "            d1[k] = v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2887fea-1f45-4b42-afe0-d9674bc2da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "patata = {}\n",
    "\n",
    "for data in data_F:\n",
    "    merge_dict (patata, data)\n",
    "    patata['OBJECT_CONTRACT_ORIGINAL'] = json.loads(data['OBJECT_CONTRACT_ORIGINAL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3556efb-6fb1-4298-83fc-b9521553e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len (data_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea179a-61a0-48c8-bf13-3ca4ae20d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(yaml.dump(patata, default_flow_style=False))\n",
    "print (json.dumps(patata, indent=4))\n",
    "\n",
    "import json\n",
    "with open('camposTotales.json', 'w') as fout:\n",
    "    json.dump(patata, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e815ff-a3d6-4629-9afd-6700da0389b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads (patata['OBJECT_CONTRACT_ORIGINAL'][0]['OBJECT_DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49349e1-481c-497a-909d-cc4b75ed5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d2145-89af-4093-ace1-f597107724f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "allkeys['CODED_DATA_SECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d42a03-940a-4b4d-83b4-e535fbae1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F[20]['CODED_DATA_SECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb8635-70bf-41fb-9e5b-d0a9c8bead5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F14 = spark.sql(\"SELECT * FROM TedFormTable WHERE FORM_ID='F14_2014'\" ).rdd.map(lambda row: row.asDict()).take(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88c599-f8d9-48cb-9695-9175b37de9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F14[20].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638939b5-04d1-48b7-9e7d-4f11940362dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F06 = spark.sql(\"SELECT * FROM TedFormTable WHERE FORM_ID='F06_2014'\" ).rdd.map(lambda row: row.asDict()).take(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f2343-2057-4a36-b813-81c7b3c3a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F06[13].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb977e7-8ee4-42a5-bb2c-e948f9c4bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F20 = spark.sql(\"SELECT * FROM TedFormTable WHERE FORM_ID='F20_2014'\" ).rdd.map(lambda row: row.asDict()).take(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87b1cf-78ad-4e1c-bb6c-6d505284af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F20[3]['DOC_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61255b26-6865-45d2-86eb-b3b3f17f61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_F20[3]['NO_DOC_OJS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d55c42-11d9-433d-af1a-635c56e3dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Número de licitaciones traducidas el inglés:\n",
    "##################\n",
    "\n",
    "translateEng =  spark.sql(\"SELECT EN_TRANSLATION FROM TedFormTable WHERE EN_TRANSLATION = true\" )\n",
    "print ('Licitaciones traducidas al inglés: %s' % translateEng.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d0f3-ed91-4e9e-8134-4ebbf39d7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Número de licitaciones por idioma:\n",
    "##################\n",
    "licByLang =  spark.sql(\"SELECT COUNT(ORIGINAL_LG) AS numlg ,ORIGINAL_LG FROM TedFormTable GROUP BY ORIGINAL_LG ORDER BY numlg DESC \" )\n",
    "print ('Licitaciones en cada idioma')\n",
    "licByLang.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171822f-b3a2-4acb-bdeb-8fb0f9637798",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Número de formularios:\n",
    "##################\n",
    "licByForm =  spark.sql(\"SELECT COUNT(FORM_ID) AS num, FORM_ID FROM TedFormTable GROUP BY FORM_ID ORDER BY num DESC\" )\n",
    "\n",
    "print ('Licitaciones por cada formulario')\n",
    "licByForm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d4fb7-c919-4ded-a02e-667638d2d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#### Información sobre licitadores:\n",
    "######################################################\n",
    "\n",
    "\n",
    "def getContractingName (part):\n",
    "    data = []\n",
    "    for p in part:\n",
    "        data.append (p['OFFICIALNAME'])\n",
    "    \n",
    "    return (data[0])\n",
    "    \n",
    "    \n",
    "def getContractingDataExists (part):    \n",
    "    return (len (part)>0)\n",
    "\n",
    "\n",
    "spark.udf.register('getContractingNameUdf', getContractingName)\n",
    "spark.udf.register('getContractingDataExistsUdf', getContractingDataExists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154184bc-e13d-4d41-9749-0f73a1d687e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "contName =  spark.sql(\"SELECT getContractingNameUdf(CONTRACTING_BODY) AS cn, ORIGINAL_LG FROM TedFormTable\")\n",
    "contName.registerTempTable(\"contractingname\")\n",
    "\n",
    "numContName = spark.sql (\"SELECT count(cn) AS num,cn,ORIGINAL_LG  FROM contractingname WHERE ORIGINAL_LG='ES' GROUP BY cn,ORIGINAL_LG ORDER BY num DESC\")\n",
    "\n",
    "print ('Principales licitadores españoles:')\n",
    "numContName.show(truncate=False)\n",
    "\n",
    "print ('Principales licitadores:')\n",
    "numContName = spark.sql (\"SELECT count(cn) AS num,cn,ORIGINAL_LG  FROM contractingname GROUP BY cn,ORIGINAL_LG ORDER BY num DESC\")\n",
    "numContName.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3ab09-275b-49cf-a45b-6e5a9b4c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cobertura, existen licitadores:')\n",
    "data = spark.sql (\"SELECT getContractingDataExistsUdf (CONTRACTING_BODY), ORIGINAL_LG  FROM TedFormTable WHERE getContractingDataExistsUdf(CONTRACTING_BODY)=false\")\n",
    "data.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbbc8a-c06f-43ef-88f3-7a0bfb63c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql (\"SELECT DATE_DISPATCH_NOTICE[0] FROM TedFormTable WHERE DATE_DISPATCH_NOTICE[0] = NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae82dd-ba4f-44d8-9e47-a791c68d1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['CONTRACTING_BODY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "def getPartData (part):\n",
    "    data = []\n",
    "    for p in part:\n",
    "        data.append ([p['TITLE'], p['REFERENCE_NUMBER']] )\n",
    "    \n",
    "    return data\n",
    "    \n",
    "spark.udf.register('getLotDataUdf', getPartData)\n",
    "\n",
    "\n",
    "def getIsLot ( lic ):\n",
    "    data = []\n",
    "    for part in lic:\n",
    "        data.append (part['LOT_DIVISION'])\n",
    "    return 'NONE' not in data\n",
    "    \n",
    "spark.udf.register('getIsLotUdf', getIsLot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tedDF.createOrReplaceTempView(\"TedFormTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translateEng =  spark.sql(\"SELECT getLotDataUdf (LOT_TRANSLATION) AS engLot, getLotDataUdf (LOT_ORIGINAL) FROM TedFormTable WHERE EN_TRANSLATION = true\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fe847",
   "metadata": {},
   "outputs": [],
   "source": [
    "translateEng.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT  ORIGINAL_LG, count(ORIGINAL_LG) AS NLIC FROM TedFormTable GROUP BY ORIGINAL_LG ORDER BY NLIC DESC\"  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT  FORM_ID, count(FORM_ID) AS NFORM FROM TedFormTable GROUP BY FORM_ID ORDER BY NFORM DESC\"  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLotes =  spark.sql(\"SELECT  URI_LIST,NO_DOC_OJS,getLotDataUdf (LOT_ORIGINAL) AS lotInfo FROM TedFormTable WHERE LOT_NUMBER>1\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLotes =  spark.sql(\"SELECT  URI_LIST,NO_DOC_OJS,getLotDataUdf (PART_ORIGINAL) AS lotInfo FROM TedFormTable WHERE PART_NUMBER>1\" ).rdd.map(lambda row: row.asDict()).take(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43deef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3580454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql(\"SELECT  *, getIsLotUdf (PART_ORIGINAL) AS lotInfo FROM TedFormTable\" ).filter(\"lotInfo=true\").rdd.map(lambda row: row.asDict()).take(40)\n",
    "\n",
    "''''\n",
    "import json\n",
    "x = data[0]['PART_ORIGINAL'][0]['OBJECT_DESCR']\n",
    "prueba = json.loads('[{\"NO_OPTIONS\"=\"null\",\"NO_EU_PROGR_RELATED\"=\"null\"}]')\n",
    "#, NUTS={@CODE=FR815}, CPV_ADDITIONAL={CPV_CODE={@CODE=45330000}}, DIRECTIVE_2014_24_EU={AC_PRICE={AC_WEIGHTING=50}]\")\n",
    "#json.loads(x)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "res = yaml.safe_load(data[0]['PART_ORIGINAL'][0]['OBJECT_DESCR'].replace('@',''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9684f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  spark.sql(\"SELECT  * FROM TedFormTable WHERE  ORIGINAL_LG='ES' AND LOT_NUMBER>1\"  ).rdd.map(lambda row: row.asDict()).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021/S 241-636641\n",
    "#636641-2021\n",
    "data = spark.sql(\"SELECT  * FROM TedFormTable WHERE DOC_ID='636641-2021'\").rdd.map(lambda row: row.asDict()).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9652643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for obj in data[0]['LOT_ORIGINAL']:\n",
    "#    print (obj['OBJECT_DESCR'])\n",
    "\n",
    "type(data[0]['LOT_ORIGINAL'][0]['OBJECT_DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print (json.dumps (data[3][ 'LOT_TRANSLATION'], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (json.dumps (data[0][ 'LOT_ORIGINAL'], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26332ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (json.dumps (data[0][ 'URI_LIST'], sort_keys=True, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
